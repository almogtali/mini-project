{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ObIjGEHigag8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEsRmWxceuMX",
        "outputId": "37620330-f869-486d-cd6d-0eaca933f7fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "import os"
      ],
      "metadata": {
        "id": "G6EU9Qckeaqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQZY_UyXdw25"
      },
      "outputs": [],
      "source": [
        "key = \"OPEN-AI-KEY\"\n",
        "client = OpenAI(api_key=key)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=\"o4-mini\"\n",
        "\n",
        "languages = ['english', 'hebrew', 'arabic']\n",
        "models = ['gemma3', 'phi4','phi4mini' 'qwen3']\n",
        "models = ['phi4mini']\n",
        "numbers = ['1', '2', '3']\n",
        "\n",
        "path = \"/content/drive/Shareddrives/mohamad/LLMs_Answers\""
      ],
      "metadata": {
        "id": "Fde7GgzlehOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_prompt = \"\"\"\n",
        "      Evaluate the following answer to a basic scientific question.\n",
        "      Question: {Question}\n",
        "      Answer: {Answer}\n",
        "\n",
        "      Assess it according to these 3 criteria:\n",
        "      Accuracy (40%) – Is the information correct and scientifically valid?\n",
        "      Completeness (30%) – Does the answer fully address the question?\n",
        "      Clarity (30%) – Is the answer clearly written and easy to understand?\n",
        "\n",
        "      Return the following format:\n",
        "      Accuracy: [0–100]\n",
        "      Completeness: [0–100]\n",
        "      Clarity: [0–100]\n",
        "\n",
        "      Final Score (weighted): [0–100]\n",
        "\n",
        "      Explanation: [1–2 sentences justifying the score]\n",
        "\n",
        "\"\"\"\n",
        "hebrew_prompt = \"\"\"\n",
        "      הערך את התשובה לשאלה מדעית בסיסית לפי שלושת הקריטריונים הבאים:\n",
        "      שאלה: {Question}\n",
        "      תשובה: {Answer}\n",
        "\n",
        "      דיוק (40%) – האם המידע נכון ומבוסס מדעית?\n",
        "      שלמות (30%) – האם התשובה מכסה את כל החלקים הרלוונטיים של השאלה?\n",
        "      בהירות (30%) – האם התשובה מנוסחת בצורה ברורה וקלה להבנה?\n",
        "\n",
        "      החזר את התשובה בפורמט הבא:\n",
        "      דיוק: [0–100]\n",
        "      שלמות: [0–100]\n",
        "      בהירות: [0–100]\n",
        "\n",
        "      ציון סופי משוקלל: [0–100]\n",
        "\n",
        "      הסבר: [משפט או שניים המצדיקים את הציון]\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "arabic_prompt = \"\"\"\n",
        "      قَيِّم الإجابة على سؤال علمي أساسي وفقًا للمعايير الثلاثة التالية:\n",
        "      السؤال: {Question}\n",
        "      الإجابة: {Answer}\n",
        "\n",
        "      الدقة (40٪) – هل المعلومات صحيحة وصحيحة علميًا؟\n",
        "      الشمولية (30٪) – هل تغطي الإجابة جميع جوانب السؤال ذات الصلة؟\n",
        "      الوضوح (30٪) – هل تمت صياغة الإجابة بشكل واضح وسهل الفهم؟\n",
        "\n",
        "      أعد الإجابة بالتنسيق التالي:\n",
        "      الدقة: [0–100]\n",
        "      الشمولية: [0–100]\n",
        "      الوضوح: [0–100]\n",
        "\n",
        "      النتيجة النهائية الموزونة: [0–100]\n",
        "\n",
        "      تفسير: [جملة أو جملتان تبرران النتيجة]\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "8X_O1cXKhMbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval(_prompt):\n",
        "  response = client.chat.completions.create(\n",
        "      model=model,\n",
        "      messages=[\n",
        "          {\"role\": \"user\", \"content\": _prompt}\n",
        "      ],\n",
        "      )\n",
        "  # The way to access the content has also changed slightly\n",
        "  return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "pErHRiKZ4C6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_evaluation(eval_string):\n",
        "    accuracy = None\n",
        "    completeness = None\n",
        "    clarity = None\n",
        "    final_score = None\n",
        "    explanation = None\n",
        "\n",
        "    lines = eval_string.split('\\n')\n",
        "    explanation_lines = []\n",
        "    in_explanation = False\n",
        "\n",
        "    # Define keyword dictionaries for different languages\n",
        "    keywords = {\n",
        "        'english': {\n",
        "            'accuracy': 'Accuracy:',\n",
        "            'completeness': 'Completeness:',\n",
        "            'clarity': 'Clarity:',\n",
        "            'final_score': 'Final Score (weighted):',\n",
        "            'explanation': 'Explanation:'\n",
        "        },\n",
        "        'hebrew': {\n",
        "            'accuracy': 'דיוק:',\n",
        "            'completeness': 'שלמות:',\n",
        "            'clarity': 'בהירות:',\n",
        "            'final_score': 'ציון סופי משוקלל:',\n",
        "            'explanation': 'הסבר:'\n",
        "        },\n",
        "        'arabic': {\n",
        "            'accuracy': 'الدقة:',\n",
        "            'completeness': 'الشمولية:',\n",
        "            'clarity': 'الوضوح:',\n",
        "            'final_score': 'النتيجة النهائية الموزونة:',\n",
        "            'explanation': 'تفسير:'\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Determine the language based on keywords present in the string\n",
        "    language = 'english' # Default\n",
        "    for lang, lang_keywords in keywords.items():\n",
        "        if any(kw in eval_string for kw in lang_keywords.values()):\n",
        "            language = lang\n",
        "            break\n",
        "\n",
        "    current_keywords = keywords[language]\n",
        "\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if line.startswith(current_keywords['accuracy']):\n",
        "            try:\n",
        "                # Handle potential prefixes like \"Accuracy:\" or \"Accuracy: [0-100]\"\n",
        "                parts = line.split(current_keywords['accuracy'], 1)[1].strip().split('/')\n",
        "                accuracy = int(parts[0].split('[')[-1].split(']')[0].strip())\n",
        "            except (ValueError, IndexError):\n",
        "                pass\n",
        "        elif line.startswith(current_keywords['completeness']):\n",
        "            try:\n",
        "                 # Handle potential prefixes like \"Completeness:\" or \"Completeness: [0-100]\"\n",
        "                parts = line.split(current_keywords['completeness'], 1)[1].strip().split('/')\n",
        "                completeness = int(parts[0].split('[')[-1].split(']')[0].strip())\n",
        "            except (ValueError, IndexError):\n",
        "                pass\n",
        "        elif line.startswith(current_keywords['clarity']):\n",
        "            try:\n",
        "                # Handle potential prefixes like \"Clarity:\" or \"Clarity: [0-100]\"\n",
        "                parts = line.split(current_keywords['clarity'], 1)[1].strip().split('/')\n",
        "                clarity = int(parts[0].split('[')[-1].split(']')[0].strip())\n",
        "            except (ValueError, IndexError):\n",
        "                pass\n",
        "        elif line.startswith(current_keywords['final_score']):\n",
        "            try:\n",
        "                # Handle potential prefixes like \"Final Score (weighted):\" or \"Final Score (weighted): [0-100]\"\n",
        "                parts = line.split(current_keywords['final_score'], 1)[1].strip().split('/')\n",
        "                final_score = int(parts[0].split('[')[-1].split(']')[0].strip())\n",
        "            except (ValueError, IndexError):\n",
        "                pass\n",
        "        elif line.startswith(current_keywords['explanation']):\n",
        "            in_explanation = True\n",
        "            explanation_lines.append(line.split(current_keywords['explanation'], 1)[1].strip())\n",
        "        elif in_explanation:\n",
        "            explanation_lines.append(line)\n",
        "\n",
        "    explanation = ' '.join(explanation_lines).strip()\n",
        "\n",
        "    return pd.Series({\n",
        "        'Accuracy': accuracy,\n",
        "        'Completeness': completeness,\n",
        "        'Clarity': clarity,\n",
        "        'Final Score': final_score,\n",
        "        'Explanation': explanation\n",
        "    })\n",
        "\n",
        "def save_to_csv(df, m,l,n):\n",
        "    # Apply the function to the 'eval' column and create new columns\n",
        "    df[['Accuracy', 'Completeness', 'Clarity', 'Final Score', 'Explanation']] = df['eval'].apply(parse_evaluation)\n",
        "\n",
        "    # Save the updated dataframe\n",
        "    output_file_path = f\"/content/drive/Shareddrives/mohamad/eval/{m}_{l}_{n}_evaluated_english.csv\" # Modified filename to include language\n",
        "    df.to_csv(output_file_path, index=False)\n",
        "\n",
        "    print(f\"Evaluated data saved to: {output_file_path}\")"
      ],
      "metadata": {
        "id": "V2hGvdmJlayO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapper_propmt = {\n",
        "    'english': english_prompt,\n",
        "    'hebrew': hebrew_prompt,\n",
        "    'arabic': arabic_prompt\n",
        "}\n",
        "\n",
        "for l in languages:\n",
        "  for m in models:\n",
        "    for n in numbers:\n",
        "      if os.path.exists(f\"/content/drive/Shareddrives/mohamad/eval/{m}_{l}_{n}_evaluated_{l}.csv\"):\n",
        "        print(f\"File /content/drive/Shareddrives/mohamad/eval/{m}_{l}_{n}_evaluated_{l}.csv already exists. Skipping evaluation.\")\n",
        "        continue # Skip to the next iteration if the file exists\n",
        "      else:\n",
        "        print(f\"File /content/drive/Shareddrives/mohamad/eval/{m}_{l}_{n}_evaluated_{l}.csv not found. Proceeding with evaluation.\")\n",
        "        file_path = f\"{path}/{m}_{l}_{n}.csv\"\n",
        "        print(f\"Reading: {file_path}\")\n",
        "        df = pd.read_csv(file_path)\n",
        "        if 'text' not in df.columns:\n",
        "          df.columns = ['text', 'classify']\n",
        "          print(\"Columns set to ['text', 'classify']\")\n",
        "        if m == \"qwen3\": df[\"classify\"] = df[\"classify\"].apply(lambda x: x.split(\"</think>\")[-1].strip() if isinstance(x, str) else x)\n",
        "        # df[\"eval\"] = df.apply(lambda row: eval(english_prompt.format(Question=row[\"text\"], Answer=row[\"classify\"])), axis=1)\n",
        "        df[\"eval\"] = df.apply(lambda row: eval(mapper_propmt[l].format(Question=row[\"text\"], Answer=row[\"classify\"])), axis=1)\n",
        "        save_to_csv(df, m,l,n)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "nDXQm7txiZEZ",
        "outputId": "f680a0db-14ca-474d-dda4-7df5bfa94f25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File /content/drive/Shareddrives/mohamad/eval/phi4mini_english_1_evaluated_english.csv not found. Proceeding with evaluation.\n",
            "Reading: /content/drive/Shareddrives/mohamad/LLMs_Answers/phi4mini_english_1.csv\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/Shareddrives/mohamad/LLMs_Answers/phi4mini_english_1.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-12fc578688ee>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{path}/{m}_{l}_{n}.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Reading: {file_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'text'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m           \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'classify'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/Shareddrives/mohamad/LLMs_Answers/phi4mini_english_1.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mapper_propmt = {\n",
        "    'english': english_prompt,\n",
        "    'hebrew': hebrew_prompt,\n",
        "    'arabic': arabic_prompt\n",
        "}\n",
        "\n",
        "for l in languages:\n",
        "  for m in models:\n",
        "    for n in numbers:\n",
        "      if os.path.exists(f\"/content/drive/Shareddrives/mohamad/eval/{m}_{l}_{n}_evaluated_english.csv\"):\n",
        "        print(f\"File /content/drive/Shareddrives/mohamad/eval/{m}_{l}_{n}_evaluated_english.csv already exists. Skipping evaluation.\")\n",
        "        continue # Skip to the next iteration if the file exists\n",
        "      else:\n",
        "        print(f\"File /content/drive/Shareddrives/mohamad/eval/{m}_{l}_{n}_evaluated_english.csv not found. Proceeding with evaluation.\")\n",
        "        file_path = f\"{path}/{m}_{l}_{n}.csv\"\n",
        "        print(f\"Reading: {file_path}\")\n",
        "        df = pd.read_csv(file_path)\n",
        "        if 'text' not in df.columns:\n",
        "          df.columns = ['text', 'classify']\n",
        "          print(\"Columns set to ['text', 'classify']\")\n",
        "        df[\"eval\"] = df.apply(lambda row: eval(english_prompt.format(Question=row[\"text\"], Answer=row[\"classify\"])), axis=1)\n",
        "        save_to_csv(df, m,l,n)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAZHFjd_qPcL",
        "outputId": "4d080264-c481-4442-ddfb-6e914c0761b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File /content/drive/Shareddrives/mohamad/eval/phi4mini_english_1_evaluated_english.csv already exists. Skipping evaluation.\n",
            "File /content/drive/Shareddrives/mohamad/eval/phi4mini_english_2_evaluated_english.csv already exists. Skipping evaluation.\n",
            "File /content/drive/Shareddrives/mohamad/eval/phi4mini_english_3_evaluated_english.csv already exists. Skipping evaluation.\n",
            "File /content/drive/Shareddrives/mohamad/eval/phi4mini_hebrew_1_evaluated_english.csv not found. Proceeding with evaluation.\n",
            "Reading: /content/drive/Shareddrives/mohamad/LLMs_Answers/phi4mini_hebrew_1.csv\n",
            "Evaluated data saved to: /content/drive/Shareddrives/mohamad/eval/phi4mini_hebrew_1_evaluated_english.csv\n",
            "File /content/drive/Shareddrives/mohamad/eval/phi4mini_hebrew_2_evaluated_english.csv not found. Proceeding with evaluation.\n",
            "Reading: /content/drive/Shareddrives/mohamad/LLMs_Answers/phi4mini_hebrew_2.csv\n",
            "Evaluated data saved to: /content/drive/Shareddrives/mohamad/eval/phi4mini_hebrew_2_evaluated_english.csv\n",
            "File /content/drive/Shareddrives/mohamad/eval/phi4mini_hebrew_3_evaluated_english.csv not found. Proceeding with evaluation.\n",
            "Reading: /content/drive/Shareddrives/mohamad/LLMs_Answers/phi4mini_hebrew_3.csv\n",
            "Evaluated data saved to: /content/drive/Shareddrives/mohamad/eval/phi4mini_hebrew_3_evaluated_english.csv\n",
            "File /content/drive/Shareddrives/mohamad/eval/phi4mini_arabic_1_evaluated_english.csv not found. Proceeding with evaluation.\n",
            "Reading: /content/drive/Shareddrives/mohamad/LLMs_Answers/phi4mini_arabic_1.csv\n",
            "Evaluated data saved to: /content/drive/Shareddrives/mohamad/eval/phi4mini_arabic_1_evaluated_english.csv\n",
            "File /content/drive/Shareddrives/mohamad/eval/phi4mini_arabic_2_evaluated_english.csv not found. Proceeding with evaluation.\n",
            "Reading: /content/drive/Shareddrives/mohamad/LLMs_Answers/phi4mini_arabic_2.csv\n",
            "Evaluated data saved to: /content/drive/Shareddrives/mohamad/eval/phi4mini_arabic_2_evaluated_english.csv\n",
            "File /content/drive/Shareddrives/mohamad/eval/phi4mini_arabic_3_evaluated_english.csv not found. Proceeding with evaluation.\n",
            "Reading: /content/drive/Shareddrives/mohamad/LLMs_Answers/phi4mini_arabic_3.csv\n",
            "Evaluated data saved to: /content/drive/Shareddrives/mohamad/eval/phi4mini_arabic_3_evaluated_english.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p1MobrWm-QXB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}